{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T15:15:35.499349Z",
     "start_time": "2024-09-16T15:15:27.419803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import math\n",
    "import torch\n",
    "import os\n",
    "\n",
    "import ipdb\n",
    "\n",
    "# Make torch deterministic\n",
    "_ = torch.manual_seed(0)\n",
    "\n",
    "\n",
    "image_size = 512\n",
    "transforms = {\n",
    "#     \"train\": Compose([\n",
    "#         RandomCrop(image_size, padding=4),\n",
    "#         RandomHorizontalFlip(),\n",
    "#         ToTensor(),\n",
    "#     ]),\n",
    "#     \"test\": ToTensor(),\n",
    "    'train': Compose([\n",
    "                ToTensor(),\n",
    "                Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize between -1 and 1\n",
    "            ]),\n",
    "    'test': Compose([\n",
    "                ToTensor(),\n",
    "                Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize between -1 and 1\n",
    "            ])\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "    dataset[split] = CIFAR10(\n",
    "        root=\"../../data/dataset/cifar10\",\n",
    "        train=(split == \"train\"),\n",
    "        download=True,\n",
    "        transform=transforms[split],\n",
    "    )\n",
    "dataloader = {}\n",
    "for split in ['train', 'test']:\n",
    "    dataloader[split] = DataLoader(\n",
    "        dataset[split],\n",
    "        batch_size=512,\n",
    "        shuffle=(split == 'train'),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last = True\n",
    "    )\n",
    "\n",
    "\n",
    "class QuantizedNet(nn.Module):\n",
    "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
    "        super(QuantizedNet,self).__init__()\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)  # After two maxpool layers, size is reduced to 8x8\n",
    "        self.fc2 = nn.Linear(512, 10)  # CIFAR-10 has 10 classes\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "def evaluate_model(model, test_loader, device ='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "net_quantized = QuantizedNet().to(device)\n",
    "net_quantized.load_state_dict(torch.load('../data/weights/best_model.pth', map_location=torch.device('cpu'), weights_only=True))\n",
    "\n",
    "quantized_model = net_quantized\n",
    "\n",
    "net_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
    "quantized_model = torch.ao.quantization.prepare(quantized_model) # Insert observers\n",
    "\n",
    "\n",
    "evaluate_model(quantized_model,dataloader['test'], device ='cpu')\n",
    "\n",
    "print(f\"Prepared Model: {quantized_model}\")\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "fquantized_model = torch.ao.quantization.convert(quantized_model)\n",
    "print(fquantized_model)\n",
    "\n",
    "\n",
    "# torch.quantize_per_tensor(X, float(self.scale),\n",
    "#                                          int(self.zero_point), self.dtype)"
   ],
   "id": "2ceda50a7dfd1e92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:03<00:00,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizedNet(\n",
      "  (quant): Quantize(scale=tensor([0.0157]), zero_point=tensor([64]), dtype=torch.quint8)\n",
      "  (conv1): QuantizedConv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.06982329487800598, zero_point=62, padding=(1, 1))\n",
      "  (conv2): QuantizedConv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.16517621278762817, zero_point=77, padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): QuantizedLinear(in_features=4096, out_features=512, scale=0.7429814338684082, zero_point=82, qscheme=torch.per_tensor_affine)\n",
      "  (fc2): QuantizedLinear(in_features=512, out_features=10, scale=0.8283320069313049, zero_point=66, qscheme=torch.per_tensor_affine)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b7b33b8e0a378840"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
