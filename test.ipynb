{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:29:03.559217Z",
     "start_time": "2024-08-15T23:29:02.429978Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "936420e43efc7cc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:31:38.538320Z",
     "start_time": "2024-08-15T23:31:38.401838Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cpu/qconv.cpp:1970 [kernel]\nQuantizedCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Convert the model to quantized version\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model_quantized \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mconvert(model_prepared, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel_quantized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Save the quantized model\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# torch.save(model_quantized.state_dict(), \"resnet18-quantized_model.pth\")\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Projects/quantization/models.py:69\u001b[0m, in \u001b[0;36mSimpleCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(x))\n\u001b[1;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/ao/nn/quantized/modules/conv.py:469\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    466\u001b[0m     _reversed_padding_repeated_twice \u001b[38;5;241m=\u001b[39m _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice,\n\u001b[1;32m    468\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cpu/qconv.cpp:1970 [kernel]\nQuantizedCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model\n",
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# model.eval()\n",
    "# from models import VGG\n",
    "\n",
    "model = SimpleCNN().to(torch.device('cpu'))\n",
    "model.eval()\n",
    "\n",
    "# Define the quantization configuration\n",
    "torch.backends.quantized.engine = 'x86'\n",
    "\n",
    "model.qconfig = torch.quantization.get_default_qconfig(\"x86\")\n",
    "\n",
    "# Prepare the model for static quantization\n",
    "model_prepared = torch.quantization.prepare(model, inplace=False)\n",
    "\n",
    "# Calibrate the model with representative data\n",
    "# Here we just run a few samples through the model\n",
    "for _ in range(10):\n",
    "    input_tensor = torch.randn(1, 3, 32, 32)\n",
    "    model_prepared(input_tensor)\n",
    "\n",
    "# Convert the model to quantized version\n",
    "model_quantized = torch.quantization.convert(model_prepared, inplace=False).to(torch.device('cpu'))\n",
    "\n",
    "model_quantized(torch.rand(1, 3, 32, 32))\n",
    "# Save the quantized model\n",
    "# torch.save(model_quantized.state_dict(), \"resnet18-quantized_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc3bb81158711588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:37:06.842655Z",
     "start_time": "2024-08-15T23:37:06.087434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing x86\n",
      "Testing fbgemm\n",
      "Testing qnnpack\n",
      "Testing onednn\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.models.quantization import resnet18\n",
    "\n",
    "# Load a pre-trained model, or define your SimpleCNN\n",
    "\n",
    "\n",
    "\n",
    "# Set the quantization engine to FBGEMM for x86 architectures\n",
    "backend = [\"x86\" , \"fbgemm\", \"qnnpack\", \"onednn\"]\n",
    "model = resnet18(pretrained=True, quantize=True)\n",
    "model.eval()\n",
    "for back in backend:\n",
    "    try:\n",
    "        print(f\"Testing {back}\")\n",
    "        torch.backends.quantized.engine = back\n",
    "    \n",
    "        # Set the quantization configuration\n",
    "        model.qconfig = torch.quantization.get_default_qconfig(back)\n",
    "        \n",
    "        # Prepare the model for static quantization\n",
    "        model_prepared = torch.quantization.prepare(model, inplace=False)\n",
    "        \n",
    "        # Calibrate the model with representative data\n",
    "        for _ in range(10):\n",
    "            input_tensor = torch.randn(1, 3, 32, 32)\n",
    "            model_prepared(input_tensor)\n",
    "        \n",
    "        # Convert the model to a quantized version\n",
    "        model_quantized = torch.quantization.convert(model_prepared, inplace=False)\n",
    "        \n",
    "        # Forward pass to test the quantized model\n",
    "        output = model_quantized(torch.rand(1, 3, 32, 32))\n",
    "        print(\"BRRRRRRRRRRRRRRRRR:\",back)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c42897ef05076b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:47:08.983028Z",
     "start_time": "2024-08-15T23:47:08.926520Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.fx as fx\n",
    "from torch.ao.quantization import (\n",
    "            get_default_qconfig_mapping,\n",
    "            get_default_qat_qconfig_mapping,\n",
    "            QConfigMapping,\n",
    "        )\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "import copy\n",
    "\n",
    "# Define or load your model\n",
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(32 * 30 * 30, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n",
    "model.eval()\n",
    "\n",
    "# Use torch.fx to symbolically trace the model\n",
    "traced_model = fx.symbolic_trace(model)\n",
    "\n",
    "# Set the quantization configuration\n",
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "torch.backends.quantized.engine = 'qnnpack'\n",
    "\n",
    "ex_inputs = torch.rand(1, 3, 32, 32)\n",
    "\n",
    "# Prepare the model using FX graph mode quantization\n",
    "prepared_model = quantize_fx.prepare_fx(traced_model, {'': model.qconfig},ex_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2170ee21f29bcffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:47:09.459442Z",
     "start_time": "2024-08-15T23:47:09.431978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calibrate with representative data\n",
    "for _ in range(10):\n",
    "    input_tensor = torch.randn(1, 3, 32, 32)\n",
    "    prepared_model(input_tensor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4379b1f87fc6a640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:47:10.301191Z",
     "start_time": "2024-08-15T23:47:10.165571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to a quantized model\n",
    "quantized_model =  torch.ao.quantization.quantize_fx.convert_fx(prepared_model)\n",
    "\n",
    "\n",
    "# Save the quantized model\n",
    "# torch.save(quantized_model.state_dict(), 'simple_cnn_quantized.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab2bfa27b26dedbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:47:11.325220Z",
     "start_time": "2024-08-15T23:47:11.230180Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d_relu.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d_relu.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cpu/qconv.cpp:1970 [kernel]\nQuantizedCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mquantized_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/ao/nn/intrinsic/quantized/modules/conv_relu.py:100\u001b[0m, in \u001b[0;36mConvReLU2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     97\u001b[0m     _reversed_padding_repeated_twice \u001b[38;5;241m=\u001b[39m _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice,\n\u001b[1;32m     99\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_relu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d_relu.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d_relu.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastXPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cpu/qconv.cpp:1970 [kernel]\nQuantizedCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:153 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:349 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastXPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:351 [backend fallback]\nAutocastCUDA: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/TensorWrapper.cpp:207 [backend fallback]\nPythonTLSSnapshot: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:161 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:165 [backend fallback]\nPythonDispatcher: registered at /opt/conda/conda-bld/pytorch_1720538643151/work/aten/src/ATen/core/PythonFallbackKernel.cpp:157 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "quantized_model.conv1(ex_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a68ed427cb71e90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:47:12.794026Z",
     "start_time": "2024-08-15T23:47:12.721795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "out = quantized_model(ex_inputs)\n",
    "print(ex_inputs.dtype, out.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5be4b2b39306ab93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:51:03.081073Z",
     "start_time": "2024-08-15T23:51:02.998425Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m intermediate_values \u001b[38;5;241m=\u001b[39m wrapped_module(input_tensor)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Display intermediate values\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mintermediate_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.fx import GraphModule\n",
    "\n",
    "class IntermediateOutputGraphModule(GraphModule):\n",
    "    def forward(self, *args, **kwargs):\n",
    "        # Dictionary to hold intermediate values\n",
    "        intermediate_outputs = {}\n",
    "\n",
    "        # Start with the input arguments\n",
    "        env = {}\n",
    "        input_iter = iter(args)\n",
    "\n",
    "        for node in self.graph.nodes:\n",
    "            if node.op == 'placeholder':\n",
    "                # Placeholder nodes correspond to inputs\n",
    "                env[node.name] = next(input_iter)\n",
    "                intermediate_outputs[node.name] = env[node.name]\n",
    "            elif node.op == 'get_attr':\n",
    "                # get_attr nodes are used to retrieve attributes (like parameters)\n",
    "                env[node.name] = getattr(self, node.target)\n",
    "                intermediate_outputs[node.name] = env[node.name]\n",
    "            elif node.op == 'call_function':\n",
    "                # call_function nodes correspond to function calls (like torch functions)\n",
    "                args = [env[arg.name] if isinstance(arg, torch.fx.Node) else arg for arg in node.args]\n",
    "                kwargs = {k: (env[v.name] if isinstance(v, torch.fx.Node) else v) for k, v in node.kwargs.items()}\n",
    "                env[node.name] = node.target(*args, **kwargs)\n",
    "                intermediate_outputs[node.name] = env[node.name]\n",
    "            elif node.op == 'call_method':\n",
    "                # call_method nodes correspond to method calls on objects (like tensor methods)\n",
    "                args = [env[arg.name] if isinstance(arg, torch.fx.Node) else arg for arg in node.args]\n",
    "                kwargs = {k: (env[v.name] if isinstance(v, torch.fx.Node) else v) for k, v in node.kwargs.items()}\n",
    "                self_obj = env[node.args[0].name]\n",
    "                method = getattr(self_obj, node.target)\n",
    "                env[node.name] = method(*args[1:], **kwargs)\n",
    "                intermediate_outputs[node.name] = env[node.name]\n",
    "            elif node.op == 'call_module':\n",
    "                # call_module nodes correspond to module calls (like layers in the model)\n",
    "                args = [env[arg.name] if isinstance(arg, torch.fx.Node) else arg for arg in node.args]\n",
    "                kwargs = {k: (env[v.name] if isinstance(v, torch.fx.Node) else v) for k, v in node.kwargs.items()}\n",
    "                submod = self.get_submodule(node.target)\n",
    "                env[node.name] = submod(*args, **kwargs)\n",
    "                intermediate_outputs[node.name] = env[node.name]\n",
    "            elif node.op == 'output':\n",
    "                # The output node represents the final output of the model\n",
    "                output = env[node.args[0].name]\n",
    "                intermediate_outputs[node.name] = output\n",
    "\n",
    "        # Return the dictionary of all intermediate outputs\n",
    "        return intermediate_outputs\n",
    "\n",
    "# Function to create the wrapped module\n",
    "def create_intermediate_output_model(model: torch.nn.Module):\n",
    "    # Convert the model into a GraphModule if it isn't already one\n",
    "    if not isinstance(model, GraphModule):\n",
    "        traced = torch.fx.symbolic_trace(model)\n",
    "    else:\n",
    "        traced = model\n",
    "\n",
    "    # Wrap the traced module\n",
    "    wrapped_module = IntermediateOutputGraphModule(traced, traced.graph)\n",
    "\n",
    "    return wrapped_module\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Assuming `quantized_model` is your original model (which could be a quantized model)\n",
    "wrapped_module = create_intermediate_output_model(quantized_model)\n",
    "\n",
    "# Example input\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Get all intermediate values\n",
    "intermediate_values = wrapped_module(input_tensor)\n",
    "\n",
    "# Display intermediate values\n",
    "for name, value in intermediate_values.items():\n",
    "    print(f\"{name}: {value.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "202c4845955a4842",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:57:19.936444Z",
     "start_time": "2024-08-15T23:57:19.855517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv1\n",
      "input: tensor([[[[ 1.5480,  1.0016,  0.5767,  ..., -2.7317,  0.4856, -0.7588],\n",
      "          [-0.3035,  0.8195, -0.7892,  ...,  0.7892, -0.3642,  2.0639],\n",
      "          [ 2.5799, -0.3946,  0.1214,  ..., -0.3642,  0.5160, -0.0911],\n",
      "          ...,\n",
      "          [-1.2141, -1.5176, -1.3051,  ..., -1.1837,  2.1853, -0.2125],\n",
      "          [ 2.8834, -1.1230,  1.1837,  ...,  0.5160, -1.7301,  1.0927],\n",
      "          [-0.5463,  0.8195,  0.6070,  ...,  1.6390,  1.3658, -1.9425]],\n",
      "\n",
      "         [[-0.9106, -0.0304,  0.5160,  ..., -1.3051,  1.2141,  0.4553],\n",
      "          [-0.6677,  1.0623, -1.8818,  ...,  1.6694,  1.0016,  0.1518],\n",
      "          [-0.2732, -0.4553, -0.5767,  ...,  0.3946,  1.3355, -1.9122],\n",
      "          ...,\n",
      "          [ 1.3962, -0.8195, -0.9713,  ..., -1.0016, -0.2428,  0.2732],\n",
      "          [ 0.7588, -2.1246,  0.8802,  ...,  0.6070, -1.9122,  0.2125],\n",
      "          [-1.8818, -0.5160, -2.2764,  ...,  0.6070,  0.0000,  0.9409]],\n",
      "\n",
      "         [[ 0.5160,  1.5176, -2.5496,  ...,  1.0927, -1.7908, -1.6997],\n",
      "          [ 1.6087, -1.9122,  0.0000,  ...,  0.2428, -1.1230,  0.1518],\n",
      "          [-0.8802, -0.1821,  0.2732,  ..., -0.8499,  0.2428,  1.0623],\n",
      "          ...,\n",
      "          [-1.3355,  0.6374, -1.2444,  ..., -0.6374,  0.0911,  0.3642],\n",
      "          [ 0.5160,  1.1534,  0.2125,  ..., -0.6374, -0.7588, -0.1821],\n",
      "          [ 2.3675,  0.2732,  0.0304,  ..., -0.0607,  0.9106, -1.5176]]]],\n",
      "       size=(1, 3, 224, 224), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.030352018773555756,\n",
      "       zero_point=133)\n",
      "output: tensor([[[0.0000, 0.8997, 0.0000,  ..., 0.0000, 0.0000, 0.7370],\n",
      "         [0.4594, 0.0000, 0.2297,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1340, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0479,  ..., 0.8997, 0.0000, 0.5360],\n",
      "         [0.9667, 0.0670, 0.4403,  ..., 0.0000, 0.6700, 0.0000],\n",
      "         [0.4116, 0.0000, 0.0000,  ..., 1.0337, 0.0191, 0.4307]],\n",
      "\n",
      "        [[0.3446, 0.3063, 0.0000,  ..., 0.2297, 0.0000, 0.0000],\n",
      "         [0.5073, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.2010, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.1340, 0.0574, 0.2297],\n",
      "         [0.0000, 0.3446, 0.0000,  ..., 0.0861, 0.4403, 0.0000],\n",
      "         [0.7944, 0.0000, 0.0000,  ..., 0.7274, 0.1723, 0.0574]],\n",
      "\n",
      "        [[0.0000, 0.3063, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0861, 0.0000,  ..., 0.0000, 0.0000, 0.2106],\n",
      "         [0.1244, 0.2871, 0.0000,  ..., 0.0000, 0.5264, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.2871, 0.0000, 0.3828],\n",
      "         [0.0000, 0.0000, 0.1149,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.2201, 0.0000,  ..., 0.0000, 0.1914, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5838, 0.0000, 0.2776,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.1149, 0.2871, 0.0861,  ..., 0.1436, 0.0000, 0.5264],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.4594, 0.3924, 0.5551],\n",
      "         [0.0383, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.1436, 0.0000,  ..., 0.0000, 0.9092, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.1677],\n",
      "         [0.1053, 0.0000, 0.0000,  ..., 0.0000, 0.7657, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0574, 0.0000],\n",
      "         ...,\n",
      "         [0.8422, 0.4020, 0.5360,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6795, 0.0000,  ..., 0.3158, 1.3878, 0.0000],\n",
      "         [1.3112, 0.0000, 0.0096,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1531],\n",
      "         [0.0000, 0.8231, 0.0000,  ..., 0.0000, 0.0000, 0.3158],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0670,  ..., 0.5455, 0.0000, 0.0000],\n",
      "         [0.1244, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.6317, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0432]]],\n",
      "       size=(32, 222, 222), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.009570932015776634,\n",
      "       zero_point=0)\n",
      "Layer fc1\n",
      "input: tensor([[0.0000, 0.8997, 0.0000,  ..., 0.0000, 0.0000, 1.0432]],\n",
      "       size=(1, 1577088), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.009570932015776634,\n",
      "       zero_point=0)\n",
      "output: tensor([-0.5727, -0.5727,  0.4486,  0.4486, -0.5727, -0.5727, -0.5727,  0.4486,\n",
      "        -0.5727, -0.5727], size=(10,), dtype=torch.quint8,\n",
      "       quantization_scheme=torch.per_tensor_affine, scale=0.004004978574812412,\n",
      "       zero_point=143)\n"
     ]
    }
   ],
   "source": [
    "activations = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activations[name] = (input, output)\n",
    "    return hook\n",
    "\n",
    "# Register hooks\n",
    "quantized_model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "quantized_model.fc1.register_forward_hook(get_activation('fc1'))\n",
    "\n",
    "# Dummy input tensor assuming input size as needed by the model\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Forward pass to collect data\n",
    "output = quantized_model(input_tensor)\n",
    "\n",
    "# Now activations dictionary contains the inputs and outputs of the registered layers\n",
    "for layer, (input, output) in activations.items():\n",
    "    print(f\"Layer {layer}\")\n",
    "    print(f\"input: {input[0]}\")# input_dtype: {input.dtype}\")\n",
    "    print(f\"output: {output[0]}\")# input_dtype: {output.dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "92fbbaa8800c784e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T00:16:51.104186Z",
     "start_time": "2024-08-16T00:16:51.100436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.009570932015776634, zero_point=0)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): QuantizedLinear(in_features=28800, out_features=10, scale=0.004004978574812412, zero_point=143, qscheme=torch.per_tensor_affine)\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2c36654acde098a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-15T23:57:02.915580Z",
     "start_time": "2024-08-15T23:57:02.896947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6413, 0.0383, 0.0479,  ..., 0.0000, 0.1244, 0.0000]],\n",
       "       size=(1, 1577088), dtype=torch.quint8,\n",
       "       quantization_scheme=torch.per_tensor_affine, scale=0.009570932015776634,\n",
       "       zero_point=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations['fc1'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "205fb572c0947e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T19:03:16.259170Z",
     "start_time": "2024-08-16T19:03:15.196991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): QuantStub(\n",
      "    (activation_post_process): HistogramObserver(min_val=-3.2918782234191895, max_val=3.3599321842193604)\n",
      "  )\n",
      "  (1): Conv2d(\n",
      "    3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (activation_post_process): HistogramObserver(min_val=-2.5597519874572754, max_val=2.638108253479004)\n",
      "  )\n",
      "  (2): ReLU()\n",
      "  (3): Conv2d(\n",
      "    64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "    (activation_post_process): HistogramObserver(min_val=-1.0260273218154907, max_val=1.0021873712539673)\n",
      "  )\n",
      "  (4): ReLU()\n",
      "  (5): DeQuantStub()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sathya/anaconda3/envs/brain/lib/python3.9/site-packages/torch/ao/quantization/observer.py:221: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization as quant\n",
    "\n",
    "def create_quantized_sequential(*lyrs):\n",
    "    # Create the quantization configuration\n",
    "    qconfig = quant.get_default_qconfig('fbgemm')\n",
    "\n",
    "    # Create the sequential layer with quantization stubs\n",
    "    stubbed_layer = nn.Sequential(\n",
    "        quant.QuantStub(),\n",
    "        *lyrs,\n",
    "        quant.DeQuantStub()\n",
    "    )\n",
    "\n",
    "    # Set the qconfig for the entire model\n",
    "    stubbed_layer.qconfig = qconfig\n",
    "\n",
    "    # Prepare the model for static quantization\n",
    "    quant.prepare(stubbed_layer, inplace=True)\n",
    "\n",
    "    return stubbed_layer\n",
    "\n",
    "# Example usage\n",
    "lyrs = [\n",
    "    nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU()\n",
    "]\n",
    "\n",
    "stubbed_layer = create_quantized_sequential(*lyrs)\n",
    "\n",
    "# To fetch qparams, you need to calibrate the model with some example data\n",
    "# This is just a placeholder, replace with your actual input data\n",
    "example_input = torch.randn(1, 3, 32, 32)\n",
    "stubbed_layer(example_input)\n",
    "print(stubbed_layer)\n",
    "# Now you can fetch the qparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "222cae5aa77505d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-16T19:03:17.060461Z",
     "start_time": "2024-08-16T19:03:17.041585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantStub: 0\n",
      "Scale: 0.05235088989138603\n",
      "Zero Point: 63\n",
      "\n",
      "DeQuantStub: 5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DeQuantStub' object has no attribute 'activation_post_process'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module, torch\u001b[38;5;241m.\u001b[39mao\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mstubs\u001b[38;5;241m.\u001b[39mDeQuantStub):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeQuantStub: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_post_process\u001b[49m\u001b[38;5;241m.\u001b[39mcalculate_qparams())\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeQuantStub doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have quantization parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/brain/lib/python3.9/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DeQuantStub' object has no attribute 'activation_post_process'"
     ]
    }
   ],
   "source": [
    "for name, module in stubbed_layer.named_modules():\n",
    "    if isinstance(module, torch.ao.quantization.stubs.QuantStub):\n",
    "        print(f\"QuantStub: {name}\")\n",
    "        if hasattr(module, 'activation_post_process'):\n",
    "            qparams = module.activation_post_process.calculate_qparams()\n",
    "            print(f\"Scale: {qparams[0].item()}\")\n",
    "            print(f\"Zero Point: {qparams[1].item()}\")\n",
    "        else:\n",
    "            print(\"Quantization parameters not yet calculated.\")\n",
    "        print()\n",
    "    elif isinstance(module, torch.ao.quantization.stubs.DeQuantStub):\n",
    "        print(f\"DeQuantStub: {name}\")\n",
    "        print(module.activation_post_process.calculate_qparams())\n",
    "        print(\"DeQuantStub doesn't have quantization parameters.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffc9d71a61ce0ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization\n",
    "\n",
    "# Define a simple model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(28*28, 10)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)  # Quantize the input\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        print(x)\n",
    "        x = self.dequant(x)  # Dequantize before returning the output\n",
    "        return x\n",
    "\n",
    "# Create a model instance\n",
    "model = SimpleModel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68fc9b1b-5c90-48e0-93c9-b7489ce968a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Specify the quantization configuration\n",
    "# 'qnnpack' is suitable for ARM devices (e.g., mobile devices)\n",
    "model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\n",
    "\n",
    "# Prepare the model for static quantization\n",
    "model_prepared = torch.quantization.prepare(model)\n",
    "# Calibrate the model with a representative dataset if needed (skipped for simplicity)\n",
    "# In practice, run a few samples through the model\n",
    "\n",
    "# Convert the model to a quantized version\n",
    "model_quantized = torch.quantization.convert(model_prepared)\n",
    "\n",
    "# The model is now quantized and can be used for inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "857ab03a-2301-48c9-a338-99785ef97c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (conv): QuantizedConv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (fc): QuantizedLinear(in_features=784, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_tensor_affine)\n",
       "  (quant): Quantize(scale=tensor([1.]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a88b638-4b12-49a5-ab08-39d454f0ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = torch.randn(1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "931f87fd-0c1d-458e-a5c2-e41aa998b87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], size=(1, 10),\n",
      "       dtype=torch.quint8, quantization_scheme=torch.per_tensor_affine,\n",
      "       scale=1.0, zero_point=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7268453-3a87-404d-8c1f-6b30927860b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantStub Observer found: <class 'torch.ao.quantization.observer.HistogramObserver'>\n",
      "Observer parameters: (tensor([1.]), tensor([0]))\n",
      "\n",
      "After calibration:\n",
      "QuantStub Observer: <class 'torch.ao.quantization.observer.HistogramObserver'>\n",
      "Calculated qparams: (tensor([0.0529]), tensor([64], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.ao.quantization as quant\n",
    "\n",
    "def create_quantized_sequential(*lyrs):\n",
    "    qconfig = quant.get_default_qconfig('fbgemm')\n",
    "    \n",
    "    stubbed_layer = nn.Sequential(\n",
    "        quant.QuantStub(),\n",
    "        *lyrs,\n",
    "        quant.DeQuantStub()\n",
    "    )\n",
    "    \n",
    "    stubbed_layer.qconfig = qconfig\n",
    "    quant.prepare(stubbed_layer, inplace=True)\n",
    "    \n",
    "    return stubbed_layer\n",
    "\n",
    "def find_quantstub_observer(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, quant.QuantStub):\n",
    "            if hasattr(module, 'activation_post_process'):\n",
    "                return module.activation_post_process\n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "lyrs = [\n",
    "    nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "    nn.ReLU()\n",
    "]\n",
    "\n",
    "stubbed_layer = create_quantized_sequential(*lyrs)\n",
    "\n",
    "# Find the observer\n",
    "observer = find_quantstub_observer(stubbed_layer)\n",
    "\n",
    "if observer:\n",
    "    print(f\"QuantStub Observer found: {type(observer)}\")\n",
    "    print(f\"Observer parameters: {observer.calculate_qparams()}\")\n",
    "else:\n",
    "    print(\"No QuantStub Observer found\")\n",
    "\n",
    "# Simulate calibration\n",
    "example_input = torch.randn(1, 3, 32, 32)\n",
    "stubbed_layer(example_input)\n",
    "\n",
    "# Check observer again after running some data through the model\n",
    "observer = find_quantstub_observer(stubbed_layer)\n",
    "if observer:\n",
    "    print(\"\\nAfter calibration:\")\n",
    "    print(f\"QuantStub Observer: {type(observer)}\")\n",
    "    print(f\"Calculated qparams: {observer.calculate_qparams()}\")\n",
    "else:\n",
    "    print(\"\\nNo QuantStub Observer found after calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801fa5b1-ab43-4a7b-b0bc-a892433853fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
